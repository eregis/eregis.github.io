---
layout: post
title: "Thoughts on Scott Alexander on the Dwarkesh Podcast"
date: 2025-04-04
mathjax: true
---

This is not a 101 space. If you don't know who Scott Alexander or Dwarkesh Patel are, that's on you.
Scott is famously
The style of this post will be excerpting parts of the transcript that I find interesting/want to react to.

The Dwarkesh Podcast has emerged as the most popular podcast. Due to his reputation for in-depth research, high quality questions,
and his connections, Dwarkesh has managed to land interviews in the broader tech sphere that other interviews haven't.

A couple months ago, he managed to get an interview with Gwern Branwen, an indepedent researcher who studies many things
including .

Dwarkesh managed to follow it up by interviewing Scott Alexander. Scott Alexander is a blogger.
While both Scott's fans and his detractors would comment on his incredibly large Internet word count,
he has shied away from podcasts. But it seems, due to a combination of Dwarkesh's reputation as well
as the need to promote his new project AI 2027, Scott has made his very first podcast appearance.

>**Scott**: Yeah, AI 2027 is our scenario trying to forecast the next few years of AI progress. We’re trying to do two things here. First of all we just want to have a concrete scenario at all. So you have all these people, Sam Altman, Dario Amodei, Elon Musk saying, “going to have AGI in three years, superintelligence in five years”. And people just think that’s crazy because right now we have chatbots that are able to do a Google search, not much more than that in a lot of ways. And so people ask, “how is it going to be AGI in three years?” What we wanted to do is provide a story, provide the transitional fossils. So start right now, go up to 2027 when there’s AGI, 2028, when there’s potentially super intelligence, show on a month-by-month level what happened. Kind of in fiction writing terms, make it feel earned.

Rationalists are a bit odd in that, while they are not *uninterested* in recent developments in machine learning, they are especially worried about the arrival of artificial generaal intelligence or "AGI" for short.